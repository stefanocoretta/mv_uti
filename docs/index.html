<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.43">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-04-08">

<title>Multivariate analyses of tongue contours from ultrasound tongue imaging. Draft v0.2</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-d4d76bf8491c20bad77d141916dc28e1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-10daa034703793678e481cc8cee6d76f.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script async="" src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>
<style>
.quarto-notebook .cell-container .cell-decorator {
  display: none;
}
</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta name="citation_title" content="Multivariate analyses of tongue contours from ultrasound tongue imaging. Draft v0.2">
<meta name="citation_author" content="Stefano Coretta">
<meta name="citation_author" content="Georges Sakr">
<meta name="citation_publication_date" content="2025-04-08">
<meta name="citation_cover_date" content="2025-04-08">
<meta name="citation_year" content="2025">
<meta name="citation_online_date" content="2025-04-08">
<meta name="citation_fulltext_html_url" content="https://stefanocoretta.github.io/mv_uti/">
<meta name="citation_language" content="en">
<meta name="citation_reference" content="citation_title=Beyond the Edge: Markerless Pose Estimation of Speech Articulators from Ultrasound and Camera Images Using DeepLabCut;,citation_author=Alan Wrench;,citation_author=Jonathan Balch-Tomes;,citation_publication_date=2022-02-02;,citation_cover_date=2022-02-02;,citation_year=2022;,citation_fulltext_html_url=https://www.mdpi.com/1424-8220/22/3/1133;,citation_issue=3;,citation_doi=10.3390/s22031133;,citation_volume=22;,citation_language=en;,citation_journal_title=Sensors;">
<meta name="citation_reference" content="citation_title=Generalised additive mixed models for dynamic analysis in linguistics: A practical introduction;,citation_author=Márton Sóskuthy;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_doi=10.48550/arXiv.1703.05339;">
<meta name="citation_reference" content="citation_title=Evaluating generalised additive mixed modelling strategies for dynamic speech analysis;,citation_author=Márton Sóskuthy;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_doi=10.1016/j.wocn.2020.101017;,citation_volume=84;,citation_journal_title=Journal of Phonetics;">
<meta name="citation_reference" content="citation_title=Hierarchical generalized additive models in ecology: An introduction with mgcv;,citation_author=Eric J. Pedersen;,citation_author=David L. Miller;,citation_author=Gavin L. Simpson;,citation_author=Noam Ross;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_doi=10.7717/peerj.6876;,citation_volume=7;,citation_journal_title=PeerJ;">
<meta name="citation_reference" content="citation_title=Analyzing dynamic phonetic data using generalized additive mixed modeling: A tutorial focusing on articulatory differences between L1 and L2 speakers of english;,citation_author=Martijn Wieling;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_doi=10.1016/j.wocn.2018.03.002;,citation_volume=70;,citation_journal_title=Journal of Phonetics;">
<meta name="citation_reference" content="citation_title=Generalized additive models;,citation_author=Trevor Hastie;,citation_author=Robert Tibshirani;,citation_publication_date=1986;,citation_cover_date=1986;,citation_year=1986;,citation_issue=3;,citation_doi=10.1201/9780203753781-6;,citation_volume=1;,citation_journal_title=Statistical Science;">
<meta name="citation_reference" content="citation_title=Generalized additive models: An introduction with r;,citation_author=Simon Wood;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;">
<meta name="citation_reference" content="citation_title=Vowel duration and consonant voicing: A production study;,citation_author=Stefano Coretta;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;">
<meta name="citation_reference" content="citation_title=An exploratory study of the voicing effect in italian and polish [data v1.0.0];,citation_author=Stefano Coretta;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_doi=10.17605/OSF.IO/8ZHKU;">
<meta name="citation_reference" content="citation_title=Longer vowel duration correlates with greater tongue root advancement at vowel offset: Acoustic and articulatory data from italian and polish;,citation_author=Stefano Coretta;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_doi=10.1121/10.0000556;,citation_volume=147;,citation_journal_title=The Journal of the Acoustical Society of America;">
<meta name="citation_reference" content="citation_title=Workshop on functional PCA for phonetics and prosody;,citation_author=Michele Gubian;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://github.com/uasolo/FPCA-phonetics-workshop;">
<meta name="citation_reference" content="citation_title=The compartmental tongue;,citation_author=Alan A. Wrench;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_issue=10S;,citation_doi=10.1044/2024_jslhr-23-00125;,citation_volume=67;,citation_journal_title=Journal of Speech, Language, and Hearing Research;">
<meta name="citation_reference" content="citation_title=Organization of tongue articulation for vowels;,citation_author=Kiyoshi Honda;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_issue=1;,citation_doi=10.1006/jpho.1996.0004;,citation_volume=24;,citation_journal_title=Journal of Phonetics;">
</head>

<body>

<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Multivariate analyses of tongue contours from ultrasound tongue imaging. Draft v0.2</h1>
          </div>

    
    <div class="quarto-title-meta-container">
      <div class="quarto-title-meta-column-start">
            <div class="quarto-title-meta-author">
          <div class="quarto-title-meta-heading">Authors</div>
          <div class="quarto-title-meta-heading">Affiliation</div>
          
                <div class="quarto-title-meta-contents">
            <p class="author">Stefano Coretta <a href="mailto:s.coretta@ed.ac.uk" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> <a href="https://orcid.org/0000-0001-9627-5532" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        University of Edinburgh
                      </p>
                  </div>
                      <div class="quarto-title-meta-contents">
            <p class="author">Georges Sakr <a href="https://orcid.org/0000-0003-3813-2669" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        University of Edinburgh
                      </p>
                  </div>
                    </div>
        
        <div class="quarto-title-meta">

                      
                <div>
            <div class="quarto-title-meta-heading">Published</div>
            <div class="quarto-title-meta-contents">
              <p class="date">April 8, 2025</p>
            </div>
          </div>
          
                
              </div>
      </div>
      <div class="quarto-title-meta-column-end quarto-other-formats-target">
      <div class="quarto-alternate-formats"><div class="quarto-title-meta-heading">Other Formats</div><div class="quarto-title-meta-contents"><p><a href="index.pdf"><i class="bi bi-file-pdf"></i>PDF (tandf)</a></p></div></div></div>
    </div>



    <div class="quarto-other-links-text-target">
    </div>  </div>
</header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#gam" id="toc-gam" class="nav-link" data-scroll-target="#gam">GAM</a>
  <ul class="collapse">
  <li><a href="#vc-coarticulation" id="toc-vc-coarticulation" class="nav-link" data-scroll-target="#vc-coarticulation">VC coarticulation</a></li>
  <li><a href="#emphaticness" id="toc-emphaticness" class="nav-link" data-scroll-target="#emphaticness">Emphaticness</a></li>
  </ul></li>
  <li><a href="#fpca" id="toc-fpca" class="nav-link" data-scroll-target="#fpca">FPCA</a>
  <ul class="collapse">
  <li><a href="#vc-coarticulation-1" id="toc-vc-coarticulation-1" class="nav-link" data-scroll-target="#vc-coarticulation-1">VC coarticulation</a></li>
  <li><a href="#emphaticness-1" id="toc-emphaticness-1" class="nav-link" data-scroll-target="#emphaticness-1">Emphaticness</a></li>
  </ul></li>
  </ul>
<div class="quarto-alternate-notebooks"><h2>Notebooks</h2><ul><li><a href="index-preview.html"><i class="bi bi-journal-code"></i>Article Notebook</a></li><li><a href="notebooks/01_prepare_data-preview.html"><i class="bi bi-journal-code"></i>Prepare data</a></li></ul></div></nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content quarto-banner-title-block" id="quarto-document-content">



  


<section id="introduction" class="level1">
<h1>Introduction</h1>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>This is a “living” draft, meaning it is work in progress. While the code is fully functional and usable, we will be updating the textual explanation and might make minor changes to the code to improve clarity. Please, if using in research, cite the version you have consulted. The version of the draft is given in the title as “Draft vX.X” where “X” are incremental digits. See citation recommendation at the bottom of the document.</p>
</div>
</div>
<p>Ultrasound Tongue Imaging (UTI) is a non-invasive technique that allows researchers to image the shape of the tongue during speech at medium temporal resolution (30-100 frames per second, XXX). Typically, the midsagittal contour of the tongue is imaged, although 3D systems exist [XXX]. Recent developments in machine learning assisted image processing has enabled faster tracking of estimated points on the tongue contour <span class="citation" data-cites="wrench2022">(<a href="#ref-wrench2022" role="doc-biblioref">A. Wrench and Balch-Tomes 2022</a>)</span>.</p>
<p><span class="citation" data-cites="wrench2022">A. Wrench and Balch-Tomes (<a href="#ref-wrench2022" role="doc-biblioref">2022</a>)</span> have trained a DeepLabCut model to estimate and track specific flesh points on the tongue contour and anatomical landmarks as captured by UTI. The model estimates 11 “knots” from the vallecula to the tongue tip, plus three muscular-skeletal knots, the hyoid bone, the mandible base and and the mental spine where the short tendon attaches. See <a href="#fig-knots" class="quarto-xref">Figure&nbsp;1</a> for a schematic illustration of the position of the tracked knots.</p>
<div id="fig-knots" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-knots-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="img/sensors-22-01133-g002.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;1: Schematic representation of the knots tracked by DeepLabCut. CC-BY Wrench and Balch-Tomes [@wrench2024]."><img src="img/sensors-22-01133-g002.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-knots-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Schematic representation of the knots tracked by DeepLabCut. CC-BY Wrench and Balch-Tomes <span class="citation" data-cites="wrench2024">(<a href="#ref-wrench2024" role="doc-biblioref">A. A. Wrench 2024</a>)</span>.
</figcaption>
</figure>
</div>
</section>
<section id="gam" class="level1">
<h1>GAM</h1>
<p>Generalised additive models (GAMs) are an extension of generalised models that allow flexible modelling of non-linear effects <span class="citation" data-cites="hastie1986 wood2006">(<a href="#ref-hastie1986" role="doc-biblioref">Hastie and Tibshirani 1986</a>; <a href="#ref-wood2006" role="doc-biblioref">Wood 2006</a>)</span>. GAMs are built upon smoothing splines functions, the components of which are multiplied by estimated coefficients to reconstruct an arbitrary time-changing curve. For a thorough introduction to GAMs we refer the reader to <span class="citation" data-cites="soskuthy2017a soskuthy2021 pedersen2019 wieling2018">(<a href="#ref-soskuthy2017a" role="doc-biblioref">Sóskuthy 2021b</a>, <a href="#ref-soskuthy2021" role="doc-biblioref">2021a</a>; <a href="#ref-pedersen2019" role="doc-biblioref">Pedersen et al. 2019</a>; <a href="#ref-wieling2018" role="doc-biblioref">Wieling 2018</a>)</span>.</p>
<p>The data tracked by DeepLabCut consists of the position on the horizontal (<em>x</em>) and vertical (<em>y</em>) axes of the fourteen knots. In this tutorial, we will focus on modelling the tongue contour based on the 11 knots from the vallecula to the tongue tip. <a href="#fig-tongue" class="quarto-xref">Figure&nbsp;2</a> illustrates the reconstructed tongue contour on the basis of the 11 knots: the shown tongue is from the offset of a vowel [o] followed by [t], uttered by a Polish speaker (see below for details on the data).</p>
<div id="cell-fig-tongue" class="cell">
<div class="cell-output-display">
<div id="fig-tongue" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tongue-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="index_files/figure-html/fig-tongue-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;2: The eleven knots on the tongue contour taken from the offset of [o] followed by [t] (Polish speaker PL04, tongue tip to the right)."><img src="index_files/figure-html/fig-tongue-1.png" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tongue-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: The eleven knots on the tongue contour taken from the offset of [o] followed by [t] (Polish speaker PL04, tongue tip to the right).
</figcaption>
</figure>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-1" href="index-preview.html#cell-fig-tongue">Source: Article Notebook</a></div>
<p>The same data is shown in <a href="#fig-tongue-xy" class="quarto-xref">Figure&nbsp;3</a>, but in a different format. Instead of a Cartesian coordinate system of X and Y values, the plot has knot number on the <em>x</em>-axis and X/Y coordinates on the <em>y</em>-axis. The X/Y coordinates thus form “trajectories” along the knots. These trajectories are the ones that can be modelled using GAMs and Functional Principal Component Analysis (FPCA). In this section, we will illustrate GAMs applied to the X/Y trajectories along the knots and how we can reconstruct the tongue contour from the modelled trajectories. We will use data from two case studies of coarticulation: vowel consonant (VC) coarticulation based on C place in Italian and Polish, and consonantal articulation of plain vs emphatic consonants in Lebanese Arabic.</p>
<div id="cell-fig-tongue-xy" class="cell">
<div class="cell-output-display">
<div id="fig-tongue-xy" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tongue-xy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="index_files/figure-html/fig-tongue-xy-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Figure&nbsp;3: The horizontal and vertical positions of the elevel knots (same data as Figure&nbsp;2)."><img src="index_files/figure-html/fig-tongue-xy-1.png" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tongue-xy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: The horizontal and vertical positions of the elevel knots (same data as <a href="#fig-tongue" class="quarto-xref">Figure&nbsp;2</a>).
</figcaption>
</figure>
</div>
</div>
</div>
<section id="vc-coarticulation" class="level2">
<h2 class="anchored" data-anchor-id="vc-coarticulation">VC coarticulation</h2>
<p>The data of the first case study, <span class="citation" data-cites="coretta2018f">Coretta (<a href="#ref-coretta2018f" role="doc-biblioref">2018</a>)</span>, comes from <span class="citation" data-cites="coretta2020b">Coretta (<a href="#ref-coretta2020b" role="doc-biblioref">2020b</a>)</span> and have been discussed in <span class="citation" data-cites="coretta2020">Coretta (<a href="#ref-coretta2020" role="doc-biblioref">2020a</a>)</span> (the analysis concerned the position of the tongue root during the duration of vowels followed by voiceless or voiced stops; in this paper we focus on tongue contours at the vowel offset). The materials are /pVCV/ words embedded in a frame sentence (<em>Dico X lentamente</em> ‘I say X slowly’ in Italian and <em>Mówię X teraz</em> ‘I say X now’ in Polish). In the /pVCV/ words, C was /t, d, k, ɡ/ and V was /a, o, u/ (in each word, the two vowels where identical, so for example <em>pata, poto, putu</em>). The data analysed here is from 9 speakers of Italian and 6 speakers of Polish (other speakers were not included due to the difficulty in processing their data with DeepLabCut).</p>
<p>[XXX Processing of data with DLC and filtering. Link to notebook].</p>
<p>The following code chunk reads the filtered data. A sample of the data is shown in <a href="#tbl-dlc-voff" class="quarto-xref">Table&nbsp;1</a>. <a href="#fig-voff" class="quarto-xref">Figure&nbsp;4</a> shows the tongue contours for each individual speaker. It is possible to notice clusters of different contours, related to each of the vowels /a, o, u/. <a href="#fig-pl04" class="quarto-xref">Figure&nbsp;5</a> zooms in on PL04 (Polish): the contours of each vowel are coloured separately, and two panels separate tongue contours taken at the offset of vowels followed by coronal (/t, d/) and velar stops (/k, ɡ/). Crucially, the variation in tongue shape at vowel offset (or closure onset) across vowels contexts is higher in the coronal than in the velar contexts. This is not surprising, giving the greater involvement of the tongue body and dorsum (the relevant articulators of vowel production) in velar than in coronal stops.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>dlc_voff_f <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">"data/coretta2018/dlc_voff_f.rds"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div id="tbl-dlc-voff" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-dlc-voff-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: A sample of the VC coarticulation data from <span class="citation" data-cites="coretta2018f">Coretta (<a href="#ref-coretta2018f" role="doc-biblioref">2018</a>)</span>.
</figcaption>
<div aria-describedby="tbl-dlc-voff-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: left;">speaker</th>
<th style="text-align: left;">word</th>
<th style="text-align: right;">X</th>
<th style="text-align: right;">Y</th>
<th style="text-align: right;">knot</th>
<th style="text-align: left;">knot_label</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">it01</td>
<td style="text-align: left;">pugu</td>
<td style="text-align: right;">-55.2105</td>
<td style="text-align: right;">-44.1224</td>
<td style="text-align: right;">0</td>
<td style="text-align: left;">Vallecula</td>
</tr>
<tr class="even">
<td style="text-align: left;">it01</td>
<td style="text-align: left;">pugu</td>
<td style="text-align: right;">-60.6994</td>
<td style="text-align: right;">-31.3486</td>
<td style="text-align: right;">1</td>
<td style="text-align: left;">Root_1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">it01</td>
<td style="text-align: left;">pugu</td>
<td style="text-align: right;">-65.1434</td>
<td style="text-align: right;">-17.7311</td>
<td style="text-align: right;">2</td>
<td style="text-align: left;">Root_2</td>
</tr>
<tr class="even">
<td style="text-align: left;">it01</td>
<td style="text-align: left;">pugu</td>
<td style="text-align: right;">-63.6757</td>
<td style="text-align: right;">-4.2022</td>
<td style="text-align: right;">3</td>
<td style="text-align: left;">Body_1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">it01</td>
<td style="text-align: left;">pugu</td>
<td style="text-align: right;">-57.2505</td>
<td style="text-align: right;">7.8483</td>
<td style="text-align: right;">4</td>
<td style="text-align: left;">Body_2</td>
</tr>
<tr class="even">
<td style="text-align: left;">it01</td>
<td style="text-align: left;">pugu</td>
<td style="text-align: right;">-44.9086</td>
<td style="text-align: right;">13.3162</td>
<td style="text-align: right;">5</td>
<td style="text-align: left;">Dorsum_1</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<div id="cell-fig-voff" class="cell">
<div class="cell-output-display">
<div id="fig-voff" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-voff-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="index_files/figure-html/fig-voff-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Figure&nbsp;4: Tongue contours of 9 Italian speakers and6 Polish speakers, taken from the offset of the first vowel in /pCVCV/ target words."><img src="index_files/figure-html/fig-voff-1.png" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-voff-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Tongue contours of 9 Italian speakers and6 Polish speakers, taken from the offset of the first vowel in /pCVCV/ target words.
</figcaption>
</figure>
</div>
</div>
</div>
<div id="cell-fig-pl04" class="cell">
<div class="cell-output-display">
<div id="fig-pl04" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pl04-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="index_files/figure-html/fig-pl04-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Figure&nbsp;5: Tongue contours of PL04 (Polish) taken from the offset of vowels followed by coronal or velar stops. Tip is on the right."><img src="index_files/figure-html/fig-pl04-1.png" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pl04-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Tongue contours of PL04 (Polish) taken from the offset of vowels followed by coronal or velar stops. Tip is on the right.
</figcaption>
</figure>
</div>
</div>
</div>
<p>We can now run a multivariate GAM to model the tongue contours. A multivariate GAM can be fitted by providing model formulae for each outcome variable (in our case, <code>X_z</code> and <code>Y_z</code>) in a list. For example <code>list(y ~ s(x), w ~ s(x))</code> would instruct <code>mgcv::gam()</code> to fit a bivariate GAM with the two outcome variables <code>y</code> and <code>w</code>. The required family is <code>mvn</code> for “multivariate normal”: <code>mvn(d = 2)</code> indicates a bivariate family (a multivariate family with two dimensions, i.e.&nbsp;two outcome variables). In the model below, we are fitting a multivariate GAM to the <em>z</em>-scored X and Y coordinates. For both outcome variables, we include a smooth over knot (<code>s(knot, ...)</code>) with a <code>by</code> variable <code>vow_place_lang</code>: this variable is built from an interaction of vowel, place and language. (XXX note on categorical interactions in GAMs). We set <code>k</code> to 5: this will usually be sufficient for X/Y coordinates of tongue contours, since they are by nature not very “wiggly” (which would require a higher <code>k</code>). We also include a factor smooth over knot for speaker (the equivalent of a non-linear random effect) with <code>s(knot, speaker, ...)</code>: since language is a between-speaker variable, we use <code>vow_place</code> as the <code>by</code> variable (<code>vow_place</code> is the interaction of vowel and place).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mgcv)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>voff_gam <span class="ot">&lt;-</span> <span class="fu">gam</span>(</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    X_z <span class="sc">~</span> vow_place_lang <span class="sc">+</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>      <span class="fu">s</span>(knot, <span class="at">by =</span> vow_place_lang, <span class="at">k =</span> <span class="dv">5</span>) <span class="sc">+</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>      <span class="fu">s</span>(knot, speaker, <span class="at">by =</span> vow_place, <span class="at">bs =</span> <span class="st">"fs"</span>, <span class="at">m =</span> <span class="dv">1</span>),</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    Y_z <span class="sc">~</span> vow_place_lang <span class="sc">+</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>      <span class="fu">s</span>(knot, <span class="at">by =</span> vow_place_lang, <span class="at">k =</span> <span class="dv">5</span>) <span class="sc">+</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>      <span class="fu">s</span>(knot, speaker, <span class="at">by =</span> vow_place, <span class="at">bs =</span> <span class="st">"fs"</span>, <span class="at">m =</span> <span class="dv">1</span>)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> dlc_voff_f,</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">mvn</span>(<span class="at">d =</span> <span class="dv">2</span>)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The model summary is not particular insightful. What we are normally interested in is the reconstructed tongue contours and in which locations they are similar of different across conditions. To the best of our knowledge, there isn’t a straightforward way to compute sensible measures of comparison, given the multidimensional nature of the model (i.e., only one or the other outcome can be inspected at a time; moreover, difference smooths, like in <span class="citation" data-cites="soskuthy2017a">Sóskuthy (<a href="#ref-soskuthy2017a" role="doc-biblioref">2021b</a>)</span> and <span class="citation" data-cites="wieling2018">Wieling (<a href="#ref-wieling2018" role="doc-biblioref">2018</a>)</span>, represent the difference of the <em>sum</em> of the outcome variables, rather than each outcome separately, Michele Gubian pers. comm.) We thus recommend to plot the predicted tongue contours and base any further inference on impressionistic observations on such predicted contours. Alas, there is also no straightforward way to plot predicted tongue contours, but to extract the predictions following a step-by-step procedure, like the one illustrated in the following paragraphs.</p>
<p>First off, one has to create a grid of predictor values to obtain predictions for. We do this with <code>expand_grid()</code> in the following code chunk. We start with unique values of <code>speaker</code>, <code>vow_place</code> and <code>knot</code> (rather than just using integers for the knots, we predict along increments of 0.1 from 0 to 10 for a more refined tongue contour). We then create the required column <code>vow_place_lang</code> by appending the language name based on the speaker ID. Note that all variables included as predictors in the model must be included in the prediction grid.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a grid of values to predict for</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>frame_voff <span class="ot">&lt;-</span> <span class="fu">expand_grid</span>(</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># All the speakers</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">speaker =</span> <span class="fu">unique</span>(dlc_voff_f<span class="sc">$</span>speaker),</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># All vowel/place combinations</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">vow_place =</span> <span class="fu">unique</span>(dlc_voff_f<span class="sc">$</span>vow_place),</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Knots from 0 to 10 by increments of 0.1</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># This gives us greater resolution along the tongue contour than just using 10 knots</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">knot =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="at">by =</span> <span class="fl">0.1</span>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>) <span class="sc">|&gt;</span> </span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">vow_place_lang =</span> <span class="fu">case_when</span>(</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>      <span class="fu">str_detect</span>(speaker, <span class="st">"it"</span>) <span class="sc">~</span> <span class="fu">paste0</span>(vow_place, <span class="st">".Italian"</span>),</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>      <span class="fu">str_detect</span>(speaker, <span class="st">"pl"</span>) <span class="sc">~</span> <span class="fu">paste0</span>(vow_place, <span class="st">".Polish"</span>)</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>With the prediction grid <code>frame_voff</code> we can now extract predictions from the model <code>voff_gam</code> with <code>predict()</code>. This function requires the GAM model object (<code>voff_gam</code>) and the prediction grid (<code>frame_off</code>). We also obtain the standard error of the prediction which we will use to calculate Confidence Intervals in the next step. Since we have used factor smooths for speaker, we now have to manually exclude these smooths from the prediction to obtain a “population” level prediction. We do this by listing the smooths to be removed in <code>excl</code>: note that the smooths must be named as they are in the summary of the model, so always check the summary to ensure you list all of the factor smooths. Finally, we rename the columns with the name of the outcome variables.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># List of factor smooths, to be excluded from prediction</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>excl <span class="ot">&lt;-</span> <span class="fu">c</span>(</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  <span class="st">"s(knot,speaker):vow_placea.coronal"</span>,</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>  <span class="st">"s(knot,speaker):vow_placeo.coronal"</span>,</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">"s(knot,speaker):vow_placeu.coronal"</span>,</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>  <span class="st">"s(knot,speaker):vow_placea.velar"</span>,</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>  <span class="st">"s(knot,speaker):vow_placeo.velar"</span>,</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>  <span class="st">"s(knot,speaker):vow_placeu.velar"</span>,</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>  <span class="st">"s.1(knot,speaker):vow_placea.coronal"</span>,</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>  <span class="st">"s.1(knot,speaker):vow_placeo.coronal"</span>,</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>  <span class="st">"s.1(knot,speaker):vow_placeu.coronal"</span>,</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>  <span class="st">"s.1(knot,speaker):vow_placea.velar"</span>,</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>  <span class="st">"s.1(knot,speaker):vow_placeo.velar"</span>,</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>  <span class="st">"s.1(knot,speaker):vow_placeu.velar"</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Get prediction from model voff_gam</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>voff_gam_p <span class="ot">&lt;-</span> <span class="fu">predict</span>(voff_gam, frame_voff, <span class="at">se.fit =</span> <span class="cn">TRUE</span>, <span class="at">exclude =</span> excl) <span class="sc">|&gt;</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.data.frame</span>() <span class="sc">|&gt;</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_tibble</span>()</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Rename columns</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(voff_gam_p) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"X"</span>, <span class="st">"Y"</span>, <span class="st">"X_se"</span>, <span class="st">"Y_se"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we have to join the prediction in <code>voff_gam_p</code> with the prediction frame, so that we have all the predictor values in the same data frame. We do so here with <code>bind_cols()</code> from the dplyr package. Note that <code>voff_gam_p</code> contains predictions for each level of the factor smooths, despite these being excluded from prediction. If you inspect the predictions for different speakers, you will find that they are the same for the same levels of <code>vow_place_lang</code>: this is because the effects of the factor smooths were removed, so <code>speaker</code> has no effect on the predicted values. This means that you can pick any Italian and Polish speaker in the predicted data frame. We do so by filtering with <code>filter(speaker %in% c("it01", "pl02"))</code>, but any other speaker would lead to the same output. We also calculate the lower and upper limits of 95% Confidence intervals (CI) for each coordinate. Note that you should interpret these CI with a grain of salt, because they are not truly multivariate, but rather represent the CI on each coordinate axis independently.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>voff_gam_p <span class="ot">&lt;-</span> <span class="fu">bind_cols</span>(frame_voff, voff_gam_p) <span class="sc">|&gt;</span> </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># pick any Italian and Polish speaker, random effects have been removed</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(speaker <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"it01"</span>, <span class="st">"pl02"</span>)) <span class="sc">|&gt;</span> </span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Calculate 95% CIs of X and Y</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">X_lo =</span> X <span class="sc">-</span> (<span class="fl">1.96</span> <span class="sc">*</span> X_se),</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">X_hi =</span> X <span class="sc">+</span> (<span class="fl">1.96</span> <span class="sc">*</span> X_se),</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">Y_lo =</span> Y <span class="sc">-</span> (<span class="fl">1.96</span> <span class="sc">*</span> Y_se),</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">Y_hi =</span> Y <span class="sc">+</span> (<span class="fl">1.96</span> <span class="sc">*</span> Y_se)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span> </span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Separate column into individual variables, for plotting later</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">separate</span>(vow_place_lang, <span class="fu">c</span>(<span class="st">"vowel"</span>, <span class="st">"place"</span>, <span class="st">"language"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><a href="#fig-voff-pred" class="quarto-xref">Figure&nbsp;6</a> and <a href="#fig-voff-ci" class="quarto-xref">Figure&nbsp;7</a> show the predicted tongue contours based on the <code>voff_gam</code> model, without and with 95% CIs respectively. As mentioned earlier, there isn’t a straightforward way to obtain any statistical measure of the difference between the contours on the multivariate plane, so we must be content with the figure.</p>
<div id="cell-fig-voff-pred" class="cell">
<div class="cell-output-display">
<div id="fig-voff-pred" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-voff-pred-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="index_files/figure-html/fig-voff-pred-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="Figure&nbsp;6: Predicted tongue contours based on a multivariate GAM. Uncertainty not shown."><img src="index_files/figure-html/fig-voff-pred-1.png" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-voff-pred-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Predicted tongue contours based on a multivariate GAM. Uncertainty not shown.
</figcaption>
</figure>
</div>
</div>
</div>
<div id="cell-fig-voff-ci" class="cell">
<div class="cell-output-display">
<div id="fig-voff-ci" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-voff-ci-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="index_files/figure-html/fig-voff-ci-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="Figure&nbsp;7: Predicted tongue contours based on a multivariate GAM, with 95% Confidence Intervals."><img src="index_files/figure-html/fig-voff-ci-1.png" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-voff-ci-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: Predicted tongue contours based on a multivariate GAM, with 95% Confidence Intervals.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="emphaticness" class="level2">
<h2 class="anchored" data-anchor-id="emphaticness">Emphaticness</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>dlc_emph_f <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">"data/sakr2025/dlc_emph_f.rds"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-fig-emph-pred" class="cell">
<div class="cell-output-display">
<div id="fig-emph-pred" class="quarto-float quarto-figure quarto-figure-center anchored" width="672">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-emph-pred-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="index_files/figure-html/fig-emph-pred-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8" title="Figure&nbsp;8: "><img src="index_files/figure-html/fig-emph-pred-1.png" id="fig-emph-pred" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-emph-pred-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8
</figcaption>
</figure>
</div>
</div>
</div>
<div id="cell-fig-emph-ci" class="cell">
<div class="cell-output-display">
<div id="fig-emph-ci" class="quarto-float quarto-figure quarto-figure-center anchored" width="672">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-emph-ci-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="index_files/figure-html/fig-emph-ci-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9" title="Figure&nbsp;9: "><img src="index_files/figure-html/fig-emph-ci-1.png" id="fig-emph-ci" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-emph-ci-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9
</figcaption>
</figure>
</div>
</div>
</div>
<div id="cell-fig-emph-part" class="cell">
<div class="cell-output-display">
<div id="fig-emph-part" class="quarto-float quarto-figure quarto-figure-center anchored" width="672">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-emph-part-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="index_files/figure-html/fig-emph-part-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10" title="Figure&nbsp;10: "><img src="index_files/figure-html/fig-emph-part-1.png" id="fig-emph-part" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-emph-part-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="fpca" class="level1">
<h1>FPCA</h1>
<section id="vc-coarticulation-1" class="level2">
<h2 class="anchored" data-anchor-id="vc-coarticulation-1">VC coarticulation</h2>
<p>We will apply Multivariate Functional Principal Component Analysis (MFPCA). The following code has been adapted from <span class="citation" data-cites="gubian2024">Gubian (<a href="#ref-gubian2024" role="doc-biblioref">2024</a>)</span>. The packages below are needed to run MFPCA (except landmarkregUtils, they are available on CRAN).</p>
<p>The format required to work through MFPCA is a “long” format with one column containing the coordinate labels (<em>x</em> or <em>y</em> coordinate) and another with the coordinate values. We can easily pivot the data with <code>pivot_longer()</code>. Note that we are using the <em>z</em>-scored coordinate values (<code>X_z</code> and <code>Y_z</code>). If you are not unsure about what the code in this section, it is always useful to inspect intermediate and final output.</p>
<p>In the second step, we create a <code>multiFunData</code> object: this is a special type of list object, with the observations of the two coordinates (<code>X_z</code> and <code>Y_z</code>) as two matrices of dimension <span class="math inline">\(N \cdot 11\)</span>, where <span class="math inline">\(N\)</span> is the number of tongue contours and <span class="math inline">\(11\)</span> is for the 11 knots returned by DLC. Three columns in the data are used to create the <code>multiFunData</code> object: one column with the id of each contour (in our data, <code>frame_id</code>), a time or series column (<code>knot</code>) and the column with the coordinate values (<code>value</code>).</p>
<p>Once we have our <code>multFunData</code> object, we can use the <code>MFPCA()</code> function to compute an MFPCA. In this tutorial we will compute the first two PCs, but you can compute up to <span class="math inline">\(K-1\)</span> PCs where <span class="math inline">\(K\)</span> is the number of DLC knots in the data.</p>
<p>We can quickly calculate the proportion of explained variance of each PC with the following code. PC1 and PC2 together explain almost 100% of the variance in our data. The higher the variance explained, the better the variance patterns in the data are captured.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.7108713 0.2891287</code></pre>
</div>
</div>
<p>The best way to assess the effect of the PC scores on the shape of the tongue contours is to plot the predicted tongue contours based on a set of representative PC scores. In order to be able to plot the predicted contours, we need to calculate them from the MFPCA object. Gubian suggests plotting predicted curves at score intervals based on fractions of the scores standard deviation. This is what the following code does.</p>
<p>The created data frame <code>pc_curves</code> has the predicted values of the X and Y coordinates <em>along the knots</em>. This is the same structure as <a href="#fig-tongue-xy" class="quarto-xref">Figure&nbsp;3</a>, with the knot number on the <em>x</em>-axis and the coordinates on the <em>y</em>-axis. Of course, what we are after is the X/Y plot of the tongue contours, rather than the knot/coordinate plot as needed to fit an MFPCA. For the sake of clarity, we first plot the predicted curves for X and Y separately. <a href="#fig-pc-curves" class="quarto-xref">Figure&nbsp;11</a> shows these. The plot is composed of four panels: the top two are the predicted curves along knot number for the Y coordinates (based on PC1 in the left panel and PC2 in the right panel). Interpreting the effect of the PCs on the X and Y coordinates separately allows one to observe vertical (Y coordinate) and horizontal (X coordinate) differences in tongue position independently. However, note that the vector of muscle contractions in the tongue are not simply along a vertical/horizontal axis <span class="citation" data-cites="honda1996 wrench2024">(<a href="#ref-honda1996" role="doc-biblioref">Honda 1996</a>; <a href="#ref-wrench2024" role="doc-biblioref">A. A. Wrench 2024</a>)</span>. Looking at a full tongue contour (in an X/Y coordinates plot) will generally prove to be more straightforward.</p>
<div id="cell-fig-pc-curves" class="cell">
<div class="cell-output-display">
<div id="fig-pc-curves" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pc-curves-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="index_files/figure-html/fig-pc-curves-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11" title="Figure&nbsp;11: Predicted curves along knot number for X and Y coordinates, as obtained from an MFPCA."><img src="index_files/figure-html/fig-pc-curves-1.png" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pc-curves-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11: Predicted curves along knot number for X and Y coordinates, as obtained from an MFPCA.
</figcaption>
</figure>
</div>
</div>
</div>
<p>In order to plot tongue contours in the X/Y coordinate system, we simply need to pivot the data to a wider format.</p>
<p><a href="#fig-contours" class="quarto-xref">Figure&nbsp;12</a> plots the predicted contours based on the the PC scores (specifically, fractions of the standard deviation of the PC scores). The <em>x</em> and <em>y</em>-axes correspond to the X and Y coordinates of the tongue contour, with the effect of PC1 in the left panel and the effect of PC2 in the right panel. A higher PC1 score (green lines in the left panel) suggest a lowering of the tongue body/dorsum and raising of the tongue tip. Since the data contains velar and coronal consonants, we take this to be capturing the velar/coronal place of articulation effect. A higher PC2 score (green lines in the right panel) corresponds to an overall higher tongue position. Considering that the back/central vowels /a, o, u/ are included in this data set, we take PC2 to be related with the effect of vowel on the tongue shape at closure onset.</p>
<div id="cell-fig-contours" class="cell">
<div class="cell-output-display">
<div id="fig-contours" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-contours-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="index_files/figure-html/fig-contours-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12" title="Figure&nbsp;12: Predicted tongue contours as obtained from an MFPCA."><img src="index_files/figure-html/fig-contours-1.png" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-contours-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12: Predicted tongue contours as obtained from an MFPCA.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Given the patterns in <a href="#fig-contours" class="quarto-xref">Figure&nbsp;12</a>, we can expect to see differences in PC2 scores based on the vowel if there is VC coarticulation. We can obtain the PC scores of each observation in the data with the following code.</p>
<p><a href="#fig-pc-scores" class="quarto-xref">Figure&nbsp;13</a> plots PC scores by language (rows), consonant place (columns) and vowel (colour). Both in Italian and Polish, we can observe a clear coarticulatory effect of /u/ on the production of coronal stops (and perhaps minor differences in /a/ vs /o/). On the other hand, the effect of vowel in velar stops seems to be minimal, again in both languages. This is not entirely surprising, since while coronal stops allow for adjustments of (and coarticulatory effect on) the tongue body, velar stops do not since it is precisely the tongue body/dorsum that is raised to produce the velar closure.</p>
<div id="cell-fig-pc-scores" class="cell">
<div class="cell-output-display">
<div id="fig-pc-scores" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pc-scores-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="index_files/figure-html/fig-pc-scores-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13" title="Figure&nbsp;13: PC1/PC2 scores by language, consonant place of articulation and vowel."><img src="index_files/figure-html/fig-pc-scores-1.png" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pc-scores-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13: PC1/PC2 scores by language, consonant place of articulation and vowel.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Once one has established which patterns each PC is capturing, PC scores can be submitted to further statistical modelling, like for example regression models where the PC scores are outcome variables and several predictors are include to assess possible differences in PC scores.</p>
</section>
<section id="emphaticness-1" class="level2">
<h2 class="anchored" data-anchor-id="emphaticness-1">Emphaticness</h2>
<p>In this section we will run an MFPCA analysis on the Lebanese Arabic data. Since the procedure is the same as in the previous section, the code will not be shown here, but can be viewed in the article notebook, at XXX.</p>
<p><a href="#fig-emph-curves-wide" class="quarto-xref">Figure&nbsp;14</a> illustrates the reconstructed tongue contours (taken from 35 ms before the CV boundary) in Lebanese Arabic, based on the MFPCA. PC1 captures the low-back/high-front diagonal movement. PC2, on the other hand, seems to be restricted to high/low movement at the back of the oral cavity. Emphatic consonants, if produced with a constricted pharynx (i.e.&nbsp;paryngealised), should have a lower PC1. If on the other hand they are produced with a raised tongue dorsum (i.e.&nbsp;velarised), they should have a lower PC2 (lower PC scores are in purple in <a href="#fig-emph-curves-wide" class="quarto-xref">Figure&nbsp;14</a>).</p>
<div id="cell-fig-emph-curves-wide" class="cell">
<div class="cell-output-display">
<div id="fig-emph-curves-wide" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-emph-curves-wide-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="index_files/figure-html/fig-emph-curves-wide-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14" title="Figure&nbsp;14: Predicted tongue contours of Lebanese Arabic coronal consonants as obtained from an MFPCA."><img src="index_files/figure-html/fig-emph-curves-wide-1.png" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-emph-curves-wide-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;14: Predicted tongue contours of Lebanese Arabic coronal consonants as obtained from an MFPCA.
</figcaption>
</figure>
</div>
</div>
</div>
<div id="cell-fig-emph-speakers" class="cell">
<div class="cell-output-display">
<div id="fig-emph-speakers" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-emph-speakers-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="index_files/figure-html/fig-emph-speakers-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15" title="Figure&nbsp;15: PC1 and PC2 scores by vowel, consonant type and speaker."><img src="index_files/figure-html/fig-emph-speakers-1.png" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-emph-speakers-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;15: PC1 and PC2 scores by vowel, consonant type and speaker.
</figcaption>
</figure>
</div>
</div>
</div>
<div id="cell-fig-emph-pc1" class="cell">
<div class="cell-output-display">
<div id="fig-emph-pc1" class="quarto-float quarto-figure quarto-figure-center anchored" width="672">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-emph-pc1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="index_files/figure-html/fig-emph-pc1-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16" title="Figure&nbsp;16: "><img src="index_files/figure-html/fig-emph-pc1-1.png" id="fig-emph-pc1" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-emph-pc1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;16
</figcaption>
</figure>
</div>
</div>
</div>
<div id="cell-fig-emph-pc2" class="cell">
<div class="cell-output-display">
<div id="fig-emph-pc2" class="quarto-float quarto-figure quarto-figure-center anchored" width="672">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-emph-pc2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="index_files/figure-html/fig-emph-pc2-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17" title="Figure&nbsp;17: "><img src="index_files/figure-html/fig-emph-pc2-1.png" id="fig-emph-pc2" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-emph-pc2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;17
</figcaption>
</figure>
</div>
</div>
</div>

</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-coretta2018f" class="csl-entry" role="listitem">
Coretta, Stefano. 2018. <span>“An Exploratory Study of the Voicing Effect in Italian and Polish [Data V1.0.0].”</span> <a href="https://doi.org/10.17605/OSF.IO/8ZHKU">https://doi.org/10.17605/OSF.IO/8ZHKU</a>.
</div>
<div id="ref-coretta2020" class="csl-entry" role="listitem">
———. 2020a. <span>“Longer Vowel Duration Correlates with Greater Tongue Root Advancement at Vowel Offset: Acoustic and Articulatory Data from Italian and Polish.”</span> <em>The Journal of the Acoustical Society of America</em> 147: 245259. <a href="https://doi.org/10.1121/10.0000556">https://doi.org/10.1121/10.0000556</a>.
</div>
<div id="ref-coretta2020b" class="csl-entry" role="listitem">
———. 2020b. <span>“Vowel Duration and Consonant Voicing: A Production Study.”</span> PhD thesis.
</div>
<div id="ref-gubian2024" class="csl-entry" role="listitem">
Gubian, Michele. 2024. <em>Workshop on Functional PCA for Phonetics and Prosody</em>. <a href="https://github.com/uasolo/FPCA-phonetics-workshop">https://github.com/uasolo/FPCA-phonetics-workshop</a>.
</div>
<div id="ref-hastie1986" class="csl-entry" role="listitem">
Hastie, Trevor, and Robert Tibshirani. 1986. <span>“Generalized Additive Models.”</span> <em>Statistical Science</em> 1 (3): 297310. <a href="https://doi.org/10.1201/9780203753781-6">https://doi.org/10.1201/9780203753781-6</a>.
</div>
<div id="ref-honda1996" class="csl-entry" role="listitem">
Honda, Kiyoshi. 1996. <span>“Organization of Tongue Articulation for Vowels.”</span> <em>Journal of Phonetics</em> 24 (1): 3952. <a href="https://doi.org/10.1006/jpho.1996.0004">https://doi.org/10.1006/jpho.1996.0004</a>.
</div>
<div id="ref-pedersen2019" class="csl-entry" role="listitem">
Pedersen, Eric J., David L. Miller, Gavin L. Simpson, and Noam Ross. 2019. <span>“Hierarchical Generalized Additive Models in Ecology: An Introduction with Mgcv.”</span> <em>PeerJ</em> 7: e6876. <a href="https://doi.org/10.7717/peerj.6876">https://doi.org/10.7717/peerj.6876</a>.
</div>
<div id="ref-soskuthy2021" class="csl-entry" role="listitem">
Sóskuthy, Márton. 2021a. <span>“Evaluating Generalised Additive Mixed Modelling Strategies for Dynamic Speech Analysis.”</span> <em>Journal of Phonetics</em> 84: 101017. <a href="https://doi.org/10.1016/j.wocn.2020.101017">https://doi.org/10.1016/j.wocn.2020.101017</a>.
</div>
<div id="ref-soskuthy2017a" class="csl-entry" role="listitem">
———. 2021b. <span>“Generalised Additive Mixed Models for Dynamic Analysis in Linguistics: A Practical Introduction.”</span> <a href="https://doi.org/10.48550/arXiv.1703.05339">https://doi.org/10.48550/arXiv.1703.05339</a>.
</div>
<div id="ref-wieling2018" class="csl-entry" role="listitem">
Wieling, Martijn. 2018. <span>“Analyzing Dynamic Phonetic Data Using Generalized Additive Mixed Modeling: A Tutorial Focusing on Articulatory Differences Between L1 and L2 Speakers of English.”</span> <em>Journal of Phonetics</em> 70: 86116. <a href="https://doi.org/10.1016/j.wocn.2018.03.002">https://doi.org/10.1016/j.wocn.2018.03.002</a>.
</div>
<div id="ref-wood2006" class="csl-entry" role="listitem">
Wood, Simon. 2006. <em>Generalized Additive Models: An Introduction with r</em>. CRC Press.
</div>
<div id="ref-wrench2024" class="csl-entry" role="listitem">
Wrench, Alan A. 2024. <span>“The Compartmental Tongue.”</span> <em>Journal of Speech, Language, and Hearing Research</em> 67 (10S): 38873913. <a href="https://doi.org/10.1044/2024_jslhr-23-00125">https://doi.org/10.1044/2024_jslhr-23-00125</a>.
</div>
<div id="ref-wrench2022" class="csl-entry" role="listitem">
Wrench, Alan, and Jonathan Balch-Tomes. 2022. <span>“Beyond the Edge: Markerless Pose Estimation of Speech Articulators from Ultrasound and Camera Images Using DeepLabCut.”</span> <em>Sensors</em> 22 (3): 1133. <a href="https://doi.org/10.3390/s22031133">https://doi.org/10.3390/s22031133</a>.
</div>
</div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{coretta2025,
  author = {Coretta, Stefano and Sakr, Georges},
  title = {Multivariate Analyses of Tongue Contours from Ultrasound
    Tongue Imaging. {Draft} V0.2},
  date = {2025-04-08},
  url = {https://stefanocoretta.github.io/mv_uti/},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-coretta2025" class="csl-entry quarto-appendix-citeas" role="listitem">
Coretta, Stefano, and Georges Sakr. 2025. <span>“Multivariate Analyses
of Tongue Contours from Ultrasound Tongue Imaging. Draft V0.2.”</span>
April 8, 2025. <a href="https://stefanocoretta.github.io/mv_uti/">https://stefanocoretta.github.io/mv_uti/</a>.
</div></div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>