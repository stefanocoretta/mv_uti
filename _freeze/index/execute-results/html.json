{
  "hash": "5776c1e5ca49a6eff7bb0bcd716a3e63",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Multivariate analyses of tongue contours from ultrasound tongue imaging\"\nauthors:\n  - name: Stefano Coretta\n    affiliation: University of Edinburgh\n    roles: [conceptualisation, data curation, methodology, software, supervision, validation, visualisation, writing, editing]\n    corresponding: true\n    orcid: 0000-0001-9627-5532\n    email: s.coretta@ed.ac.uk\n  - name: Georges Sakr\n    affiliation: University of Edinburgh\n    orcid: 0000-0003-3813-2669\n    roles: [data curation, methodology, writing, editing]\nbibliography: references.bib\nexecute: \n  echo: true\n---\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\ntheme_set(theme_light())\nlibrary(knitr)\n```\n:::\n\n\n\n\n## Introduction\n\nUltrasound Tongue Imaging (UTI) is a non-invasive technique that allows researchers to image the shape of the tongue during speech at medium temporal resolution (30-100 frames per second, XXX). Typically, the midsagittal contour of the tongue is imaged, although 3D systems exist \\[XXX\\]. Recent developments in machine learning assisted image processing has enabled faster tracking of estimated points on the tongue contour [@wrench2022].\n\n@wrench2022 have trained a DeepLabCut model to estimate and track specific flesh points on the tongue contour and anatomical landmarks as captured by UTI. The model estimates 11 \"knots\" from the vallecula to the tongue tip, plus three muscular-skeletal knots, the hyoid bone, the mandible base and and the mental spine where the short tendon attaches. See @fig-knots for a schematic illustration of the position of the tracked knots.\n\n![Schematic representation of the knots tracked by DeepLabCut. CC-BY Wrench and Balch-Tomes [@wrench2024].](img/sensors-22-01133-g002.jpg){#fig-knots fig-align=\"center\"}\n\n## GAM\n\nGeneralised additive models (GAMs) are an extension of generalised models that allow flexible modelling of non-linear effects [@hastie1986; @wood2006]. GAMs are built upon smoothing splines functions, the components of which are multiplied by estimated coefficients to reconstruct an arbitrary time-changing curve. For a thorough introduction to GAMs we refer the reader to [@soskuthy2017a; @soskuthy2021; @pedersen2019; @wieling2018].\n\nThe data tracked by DeepLabCut consists of the position on the horizontal (*x*) and vertical (*y*) axes of the fourteen knots. In this tutorial, we will focus on modelling the tongue contour based on the 11 knots from the vallecula to the tongue tip. @fig-tongue illustrates the reconstructed tongue contour on the basis of the 11 knots: the shown tongue is from the offset of a vowel \\[o\\] followed by \\[t\\], uttered by a Polish speaker (see below for details on the data).\n\n\n\n\n::: {#cell-fig-tongue .cell}\n\n```{.r .cell-code .hidden}\ndlc_voff_f <- readRDS(\"data/coretta2018/dlc_voff_f.rds\")\n\ndlc_voff_f |> \n  filter(speaker == \"pl04\", frame_id == 432) |> \n  ggplot(aes(X, Y, group = frame_id)) +\n  geom_point() +\n  geom_path() +\n  coord_fixed() +\n  labs(x = \"X (mm)\", y = \"Y (mm)\")\n```\n\n::: {.cell-output-display}\n![The eleven knots on the tongue contour taken from the offset of [o] followed by [t] (Polish speaker PL04, tongue tip to the right).](index_files/figure-html/fig-tongue-1.png){#fig-tongue width=672}\n:::\n:::\n\n\n\n\nThe same data is shown in @fig-tongue-xy, but in a different format. Instead of a Cartesian coordinate system of X and Y values, the plot has knot number on the *x*-axis and X/Y coordinates on the *y*-axis. The X/Y coordinates thus form \"trajectories\" along the knots. These trajectories are the ones that can be modelled using GAMs and Functional Principal Component Analysis (FPCA). In this section, we will illustrate GAMs applied to the X/Y trajectories along the knots and how we can reconstruct the tongue contour from the modelled trajectories. We will use data from two case studies of coarticulation: vowel consonant (VC) coarticulation based on C place in Italian and Polish, and consonantal articulation of plain vs emphatic consonants in Lebanese Arabic.\n\n\n\n\n::: {#cell-fig-tongue-xy .cell}\n\n```{.r .cell-code .hidden}\ndlc_voff_f |> \n  filter(speaker == \"pl04\", frame_id == 432) |> \n  dplyr::select(knot, X, Y) |> \n  pivot_longer(c(X,Y)) |> \n  ggplot(aes(knot + 1, value)) +\n  geom_point() +\n  geom_path() +\n  facet_grid(rows = vars(name)) +\n  scale_x_continuous(breaks = 1:11) +\n  labs(x = \"Knot\", y = \"Position (mm)\")\n```\n\n::: {.cell-output-display}\n![The horizontal and vertical positions of the elevel knots (same data as @fig-tongue).](index_files/figure-html/fig-tongue-xy-1.png){#fig-tongue-xy width=672}\n:::\n:::\n\n\n\n\n### VC coarticulation\n\nThe data of the first case study, @coretta2018f, comes from @coretta2020b and have been discussed in @coretta2020 (the analysis concerned the position of the tongue root during the duration of vowels followed by voiceless or voiced stops; in this paper we focus on tongue contours at the vowel offset). The materials are /pVCV/ words embedded in a frame sentence (*Dico X lentamente* 'I say X slowly' in Italian and *Mówię X teraz* 'I say X now' in Polish). In the /pVCV/ words, C was /t, d, k, ɡ/ and V was /a, o, u/ (in each word, the two vowels where identical, so for example *pata, poto, putu*). The data analysed here is from 9 speakers of Italian and 6 speakers of Polish (other speakers were not included due to the difficulty in processing their data with DeepLabCut).\n\n\\[XXX Processing of data with DLC and filtering. Link to notebook\\].\n\nThe following code chunk reads the filtered data. A sample of the data is shown in @tbl-dlc-voff. @fig-voff shows the tongue contours for each individual speaker. It is possible to notice clusters of different contours, related to each of the vowels /a, o, u/. @fig-pl04 zooms in on PL04 (Polish): the contours of each vowel are coloured separately, and two panels separate tongue contours taken at the offset of vowels followed by coronal (/t, d/) and velar stops (/k, ɡ/). Crucially, the variation in tongue shape at vowel offset (or closure onset) across vowels contexts is higher in the coronal than in the velar contexts. This is not surprising, giving the greater involvement of the tongue body and dorsum (the relevant articulators of vowel production) in velar than in coronal stops.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndlc_voff_f <- readRDS(\"data/coretta2018/dlc_voff_f.rds\")\n```\n:::\n\n::: {#tbl-dlc-voff .cell tbl-cap='A sample of the VC coarticulation data from @coretta2018f.'}\n\n```{.r .cell-code .hidden}\nhead(dlc_voff_f |> select(speaker, word, X, Y, knot, knot_label)) |> kable()\n```\n\n::: {.cell-output-display}\n\n\n|speaker |word |        X|        Y| knot|knot_label |\n|:-------|:----|--------:|--------:|----:|:----------|\n|it01    |pugu | -55.2105| -44.1224|    0|Vallecula  |\n|it01    |pugu | -60.6994| -31.3486|    1|Root_1     |\n|it01    |pugu | -65.1434| -17.7311|    2|Root_2     |\n|it01    |pugu | -63.6757|  -4.2022|    3|Body_1     |\n|it01    |pugu | -57.2505|   7.8483|    4|Body_2     |\n|it01    |pugu | -44.9086|  13.3162|    5|Dorsum_1   |\n\n\n:::\n:::\n\n::: {#cell-fig-voff .cell}\n\n```{.r .cell-code .hidden}\ndlc_voff_f |> \n  ggplot(aes(X_z, Y_z, group = frame_id)) +\n  geom_path(alpha = 0.25) +\n  coord_fixed() +\n  facet_wrap(vars(speaker), ncol = 5)\n```\n\n::: {.cell-output-display}\n![Tongue contours of 9 Italian speakers and6 Polish speakers, taken from the offset of the first vowel in /pCVCV/ target words.](index_files/figure-html/fig-voff-1.png){#fig-voff width=672}\n:::\n:::\n\n::: {#cell-fig-pl04 .cell}\n\n```{.r .cell-code .hidden}\ndlc_voff_f |> \n  filter(speaker == \"pl04\") |> \n  ggplot(aes(X_z, Y_z, group = frame_id, colour = vowel)) +\n  geom_path(alpha = 0.5) +\n  coord_fixed() +\n  facet_grid(cols = vars(c2_place)) +\n  labs(x = \"X (z-scores)\", \"Y (z-scores)\")\n```\n\n::: {.cell-output-display}\n![Tongue contours of PL04 (Polish) taken from the offset of vowels followed by coronal or velar stops. Tip is on the right.](index_files/figure-html/fig-pl04-1.png){#fig-pl04 width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nlibrary(mgcv)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading required package: nlme\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttaching package: 'nlme'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nThe following object is masked from 'package:dplyr':\n\n    collapse\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nThis is mgcv 1.9-1. For overview type 'help(\"mgcv-package\")'.\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nfi <- \"data/cache/voff_gam.rds\"\n\nif (file.exists(fi)) {\n  voff_gam <- readRDS(fi)\n} else {\n  voff_gam <- gam(\n    list(\n      X_z ~ vow_place_lang +\n        s(knot, by = vow_place_lang, k = 5) +\n        s(knot, speaker, by = vow_place, bs = \"fs\", m = 1),\n      Y_z ~ vow_place_lang +\n        s(knot, by = vow_place_lang, k = 5) +\n        s(knot, speaker, by = vow_place, bs = \"fs\", m = 1)\n    ),\n    data = dlc_voff_f,\n    family = mvn(d = 2)\n  )\n  \n  saveRDS(voff_gam, fi)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nframe_voff <- expand_grid(\n  speaker = unique(dlc_voff_f$speaker),\n  vow_place_lang = unique(dlc_voff_f$vow_place_lang),\n  knot = seq(0, 10, by = 0.1)\n) |> \n  mutate(\n    vow_place = str_remove(vow_place_lang, \"\\\\.Italian\"),\n    vow_place = str_remove(vow_place, \"\\\\.Polish\"),\n  )\n\nexcl <- c(\n  \"s(knot,speaker):vow_placea.coronal\",\n  \"s(knot,speaker):vow_placeo.coronal\",\n  \"s(knot,speaker):vow_placeu.coronal\",\n  \"s(knot,speaker):vow_placea.velar\",\n  \"s(knot,speaker):vow_placeo.velar\",\n  \"s(knot,speaker):vow_placeu.velar\",\n  \"s.1(knot,speaker):vow_placea.coronal\",\n  \"s.1(knot,speaker):vow_placeo.coronal\",\n  \"s.1(knot,speaker):vow_placeu.coronal\",\n  \"s.1(knot,speaker):vow_placea.velar\",\n  \"s.1(knot,speaker):vow_placeo.velar\",\n  \"s.1(knot,speaker):vow_placeu.velar\"\n)\n\nvoff_gam_p <- predict(voff_gam, frame_voff, se.fit = TRUE, exclude = excl) |>\n  as.data.frame() |>\n  as_tibble()\ncolnames(voff_gam_p) <- c(\"X\", \"Y\", \"X_se\", \"Y_se\")\n\nvoff_gam_p <- bind_cols(frame_voff, voff_gam_p) |> \n  # pick any speaker, random effects have been removed\n  filter(speaker == \"it01\") |> \n  mutate(\n    X_lo = X - (1.96 * X_se),\n    X_hi = X + (1.96 * X_se),\n    Y_lo = Y - (1.96 * Y_se),\n    Y_hi = Y + (1.96 * Y_se)\n  ) |> \n  separate(vow_place_lang, c(\"vowel\", \"place\", \"language\"))\n```\n:::\n\n::: {#cell-fig-voff-pred .cell}\n\n```{.r .cell-code .hidden}\nvoff_gam_p |> \n  ggplot(aes(X, Y, colour = vowel)) +\n  geom_point(alpha = 0.5) +\n  facet_grid(cols = vars(place), rows = vars(language)) +\n  coord_fixed() +\n  labs(\n    x = \"X (z-scores)\",\n    y = \"Y (z-scores)\"\n  )\n```\n\n::: {.cell-output-display}\n![Predicted tongue contours based on a multivariate GAM. Uncertainty not shown.](index_files/figure-html/fig-voff-pred-1.png){#fig-voff-pred width=672}\n:::\n:::\n\n::: {#cell-fig-voff-ci .cell}\n\n```{.r .cell-code .hidden}\nvoff_gam_p |> \n  group_by(place, vowel, language) |> \n  mutate(\n    Y_lo = ifelse(Y_lo > min(Y), Y_lo, NA),\n    X_hi = ifelse(X_hi < max(X), X_hi, NA),\n  ) |> \n  ggplot(aes(X, Y, colour = vowel)) +\n  geom_errorbarh(aes(xmin = X_lo, xmax = X_hi), alpha = 0.5) +\n  geom_errorbar(aes(ymin = Y_lo, ymax = Y_hi), alpha = 0.5) +\n  geom_point(size = 1, alpha = 0.75) +\n  scale_color_brewer(type = \"qual\", palette = \"Dark2\") +\n  coord_fixed() +\n  facet_grid(cols = vars(place), rows = vars(language)) +\n  theme_light() +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: Removed 57 rows containing missing values or values outside the scale range\n(`geom_errorbarh()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![Predicted tongue contours based on a multivariate GAM, with 95% Confidence Intervals.](index_files/figure-html/fig-voff-ci-1.png){#fig-voff-ci width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nframe_voff <- expand_grid(\n  speaker = unique(dlc_voff_f$speaker),\n  vow_place_lang = unique(dlc_voff_f$vow_place_lang),\n  knot = seq(0, 10)\n) |> \n  mutate(\n    vow_place = str_remove(vow_place_lang, \"\\\\.Italian\"),\n    vow_place = str_remove(vow_place, \"\\\\.Polish\"),\n  )\n\npred_grid_a <- filter(\n  frame_voff, vow_place_lang == \"a.coronal.Italian\",\n  speaker == \"it01\"\n)\npred_grid_b <- filter(\n  frame_voff, vow_place_lang == \"u.coronal.Italian\",\n  speaker == \"it01\"\n)\n\npred_a <- predict.gam(voff_gam, pred_grid_a, type = \"lpmatrix\") |> \n  as_tibble() |> \n  mutate(\n    across(starts_with(\"s(knot,speaker)\"), ~0)\n  ) |> \n  as.matrix()\npred_a[,1:870] <- 0\n\npred_b <- predict.gam(voff_gam, pred_grid_b, type = \"lpmatrix\") |> \n  as_tibble() |> \n  mutate(\n    across(starts_with(\"s(knot,speaker)\"), ~0)\n  ) |> \n  as.matrix()\npred_b[,1:870] <- 0\n\npred_diff <- pred_a - pred_b\ndiff <- as.vector(pred_diff %*% stats::coef(voff_gam))\n\nse <- sqrt(rowSums((pred_diff %*% stats::vcov(voff_gam)) * pred_diff))\n\ndiff_out <- pred_grid_a\ndiff_out$diff <- diff\ndiff_out$se <- se\ndiff_out$lower_ci <- diff - se * 1.96\ndiff_out$upper_ci <- diff + se * 1.96\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ndiff_out |> \n  ggplot(aes(knot, diff)) +\n  geom_hline(yintercept = 0) +\n  geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci), alpha = 0.5) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\n\n### Emphaticness\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ndlc_emph_f <- readRDS(\"data/sakr2025/dlc_emph_f.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nlibrary(mgcv)\n\nfi <- \"data/cache/emph_gam.rds\"\n\nif (file.exists(fi)) {\n  emph_gam <- readRDS(fi)\n} else {\n  emph_gam <- gam(\n    list(\n      X_z ~ vow_emph +\n        s(knot, by = vow_emph, k = 5) +\n        s(knot, participant, by = vow_emph, bs = \"fs\", m = 1, k = 5),\n      Y_z ~ vow_emph +\n        s(knot, by = vow_emph, k = 5) +\n        s(knot, participant, by = vow_emph, bs = \"fs\", m = 1, k = 5)\n    ),\n    data = dlc_emph_f,\n    family = mvn(d = 2)\n  )\n  \n  saveRDS(emph_gam, fi)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nframe_emph <- expand_grid(\n  participant = unique(dlc_emph_f$participant),\n  vow_emph = unique(dlc_emph_f$vow_emph),\n  knot = seq(0, 10, by = 0.1)\n)\n\nexcl <- c(\n  \"s(Knot,participant):vow_emphA.Emphatic\",\n  \"s(Knot,participant):vow_emphE.Emphatic\",\n  \"s(Knot,participant):vow_emphI.Emphatic\",\n  \"s(Knot,participant):vow_emphO.Emphatic\",\n  \"s(Knot,participant):vow_emphU.Emphatic\",\n  \"s.1(Knot,participant):vow_emphA.Emphatic\",\n  \"s.1(Knot,participant):vow_emphE.Emphatic\",\n  \"s.1(Knot,participant):vow_emphI.Emphatic\",\n  \"s.1(Knot,participant):vow_emphO.Emphatic\",\n  \"s.1(Knot,participant):vow_emphU.Emphatic\",\n  \"s(Knot,participant):vow_emphA.Plain\",\n  \"s(Knot,participant):vow_emphE.Plain\",\n  \"s(Knot,participant):vow_emphI.Plain\",\n  \"s(Knot,participant):vow_emphO.Plain\",\n  \"s(Knot,participant):vow_emphU.Plain\",\n  \"s.1(Knot,participant):vow_emphA.Plain\",\n  \"s.1(Knot,participant):vow_emphE.Plain\",\n  \"s.1(Knot,participant):vow_emphI.Plain\",\n  \"s.1(Knot,participant):vow_emphO.Plain\",\n  \"s.1(Knot,participant):vow_emphU.Plain\"\n)\n\nemph_gam_p <- predict(emph_gam, frame_emph, se.fit = TRUE, exclude = excl) |>\n  as.data.frame() |>\n  as_tibble()\ncolnames(emph_gam_p) <- c(\"X\", \"Y\", \"X_se\", \"Y_se\")\n\nemph_gam_p <- bind_cols(frame_emph, emph_gam_p) |> \n  # pick any speaker, random effects have been removed\n  filter(participant == \"Sak\") |> \n  mutate(\n    X_lo = X - (1.96 * X_se),\n    X_hi = X + (1.96 * X_se),\n    Y_lo = Y - (1.96 * Y_se),\n    Y_hi = Y + (1.96 * Y_se)\n  ) |> \n  separate(vow_emph, c(\"vowel\", \"emph\"))\n```\n:::\n\n::: {#cell-fig-emph-pred .cell}\n\n```{.r .cell-code .hidden}\nemph_gam_p |> \n  ggplot(aes(X, Y, colour = emph)) +\n  geom_point() +\n  facet_grid(cols = vars(vowel)) +\n  coord_fixed() +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/fig-emph-pred-1.png){#fig-emph-pred width=672}\n:::\n:::\n\n::: {#cell-fig-emph-ci .cell}\n\n```{.r .cell-code .hidden}\nemph_gam_p |> \n  ggplot(aes(X, Y, colour = emph)) +\n  geom_errorbarh(aes(xmin = X_lo, xmax = X_hi), alpha = 0.25) +\n  geom_errorbar(aes(ymin = Y_lo, ymax = Y_hi), alpha = 0.25) +\n  geom_point(size = 1, alpha = 0.75) +\n  scale_color_brewer(type = \"qual\", palette = \"Dark2\") +\n  coord_fixed() +\n  facet_grid(cols = vars(vowel)) +\n  theme_light() +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/fig-emph-ci-1.png){#fig-emph-ci width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nemph_gam_p_2 <- predict(emph_gam, frame_emph, se.fit = TRUE) |>\n  as.data.frame() |>\n  as_tibble()\ncolnames(emph_gam_p_2) <- c(\"X\", \"Y\", \"X_se\", \"Y_se\")\n\nemph_gam_p_2 <- bind_cols(frame_emph, emph_gam_p_2) |>\n  mutate(\n    X_lo = X - (1.96 * X_se),\n    X_hi = X + (1.96 * X_se),\n    Y_lo = Y - (1.96 * Y_se),\n    Y_hi = Y + (1.96 * Y_se)\n  ) |> \n  separate(vow_emph, c(\"vowel\", \"emph\"))\n```\n:::\n\n::: {#cell-fig-emph-part .cell}\n\n```{.r .cell-code .hidden}\nemph_gam_p_2 |> \n  ggplot(aes(X, Y, colour = emph)) +\n  geom_errorbarh(aes(xmin = X_lo, xmax = X_hi), alpha = 0.5) +\n  geom_errorbar(aes(ymin = Y_lo, ymax = Y_hi), alpha = 0.5) +\n  # geom_point() +\n  facet_grid(rows = vars(participant), cols = vars(vowel)) +\n  coord_fixed()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/fig-emph-part-1.png){#fig-emph-part width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nframe_emph <- expand_grid(\n  participant = unique(dlc_emph_f$participant),\n  vow_emph = unique(dlc_emph_f$vow_emph),\n  knot = 0:10\n)\n\npred_grid_a <- filter(\n  frame_emph, vow_emph == \"E.plain\",\n  participant == \"Sak\"\n)\npred_grid_b <- filter(\n  frame_emph, vow_emph == \"E.emphatic\",\n  participant == \"Sak\"\n)\n\npred_a <- predict.gam(emph_gam, pred_grid_a, type = \"lpmatrix\") |> \n  as_tibble() |> \n  mutate(\n    across(starts_with(\"s(knot,participant)\"), ~0)\n  ) |> \n  as.matrix()\n# pred_a[,301:603] <- 0\npred_a[,1:300] <- 0\n\npred_b <- predict.gam(emph_gam, pred_grid_b, type = \"lpmatrix\") |> \n  as_tibble() |> \n  mutate(\n    across(starts_with(\"s(knot,participant)\"), ~0)\n  ) |> \n  as.matrix()\n# pred_b[,301:603] <- 0\npred_b[,1:300] <- 0\n\npred_diff <- pred_a - pred_b\ndiff <- as.vector(pred_diff %*% stats::coef(emph_gam))\n\nse <- sqrt(rowSums((pred_diff %*% stats::vcov(emph_gam)) * pred_diff))\n\ndiff_out <- pred_grid_a\ndiff_out$diff <- diff\ndiff_out$se <- se\ndiff_out$lower_ci <- diff - se * 1.96\ndiff_out$upper_ci <- diff + se * 1.96\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ndiff_out |> \n  ggplot(aes(knot, diff)) +\n  geom_hline(yintercept = 0) +\n  geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci), alpha = 0.5) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n\n## FPCA\n\n### VC coarticulation\n\nWe will apply Multivariate Functional Principal Component Analysis (MFPCA). The following code has been adapted from @gubian2024. The packages below are needed to run MFPCA (except landmarkregUtils, they are available on CRAN).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nlibrary(fda)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading required package: splines\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading required package: fds\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading required package: rainbow\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading required package: MASS\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttaching package: 'MASS'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nThe following object is masked from 'package:dplyr':\n\n    select\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading required package: pcaPP\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading required package: RCurl\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttaching package: 'RCurl'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nThe following object is masked from 'package:tidyr':\n\n    complete\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading required package: deSolve\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttaching package: 'fda'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nThe following object is masked from 'package:graphics':\n\n    matplot\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(funData)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttaching package: 'funData'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nThe following object is masked from 'package:ggplot2':\n\n    ggplot\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nThe following object is masked from 'package:stats':\n\n    integrate\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(MFPCA)\n# install.packages(\"remotes\")\n# remotes::install_github(\"uasolo/landmarkregUtils\")\nlibrary(landmarkregUtils)\n```\n:::\n\n\n\n\nThe format required to work through MFPCA is a \"long\" format with one column containing the coordinate labels (*x* or *y* coordinate) and another with the coordinate values. We can easily pivot the data with `pivot_longer()`. Note that we are using the *z*-scored coordinate values (`X_z` and `Y_z`). If you are not unsure about what the code in this section, it is always useful to inspect intermediate and final output.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ndlc_voff_long <- dlc_voff_f |> \n  # Select relevant columns\n  dplyr::select(X_z, Y_z, frame_id, knot, vowel, c2_place, language, speaker) |> \n  # Pivot data to longer format. Saves coordinate labels to column `dim`\n  pivot_longer(c(X_z, Y_z), names_to = \"dim\")\n```\n:::\n\n\n\n\nIn the second step, we create a `multiFunData` object: this is a special type of list object, with the observations of the two coordinates (`X_z` and `Y_z`) as two matrices of dimension $N \\cdot 11$, where $N$ is the number of tongue contours and $11$ is for the 11 knots returned by DLC. Three columns in the data are used to create the `multiFunData` object: one column with the id of each contour (in our data, `frame_id`), a time or series column (`knot`) and the column with the coordinate values (`value`).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncurves_fun_2d <- lapply(\n  c(\"X_z\", \"Y_z\"),\n  function(y) {\n    long2irregFunData(\n      dlc_voff_long |> filter(dim == {{y}}),\n      # Tongue contour ID\n      id = \"frame_id\",\n      # Knot column\n      time = \"knot\",\n      # X/Y coordinate values\n      value = \"value\"\n    ) |> \n    as.funData()\n  }\n) |> \n  multiFunData()\n```\n:::\n\n\n\n\nOnce we have our `multFunData` object, we can use the `MFPCA()` function to compute an MFPCA. In this tutorial we will compute the first two PCs, but you can compute up to $K-1$ PCs where $K$ is the number of DLC knots in the data.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Number of PC to compute\nn_pc <- 2\n\n# Compute MFPCA\nmfpca <- MFPCA(\n  curves_fun_2d,\n  M = n_pc,\n  uniExpansions = list(list(type = \"uFPCA\"), list(type = \"uFPCA\"))\n)\n```\n:::\n\n\n\n\nWe can quickly calculate the proportion of explained variance of each PC with the following code. PC1 and PC2 together explain almost 100% of the variance in our data. The higher the variance explained, the better the variance patterns in the data are captured.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Proportion of explained variance\nmfpca$values  / sum(mfpca$values)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.7108713 0.2891287\n```\n\n\n:::\n:::\n\n\n\n\nThe best way to assess the effect of the PC scores on the shape of the tongue contours is to plot the predicted tongue contours based on a set of representative PC scores. In order to be able to plot the predicted contours, we need to calculate them from the MFPCA object. Gubian suggests plotting predicted curves at score intervals based on fractions of the scores standard deviation. This is what the following code does.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Ge the PC score SD\nsd_fun <- sqrt(mfpca$values)\n\n# PC curves to be plotted\npc_curves <- expand_grid(\n  PC = 1:n_pc,\n  dim = 1:2,\n  # Set the SD fraction, from -1 SD to +1 SD, with increments by 0.25\n  sd_frac = seq(-1, 1, by = 0.25)\n) |>\n  group_by(PC, dim, sd_frac) |>\n  # We can now calculate the predicted contour with funData2long1().\n  # reframe() is needed because the funData2long1() function returns a data frame\n  # the has more rows than the original.\n  reframe(\n    funData2long1(\n      mfpca$meanFunction[[dim]] +\n        sd_frac * sd_fun[PC] * mfpca$functions[[dim]][PC],\n      time = \"knot\", value = \"value\"\n    )\n  ) |> \n  # We relabel the dimensions\n  mutate(\n    dim = factor(dim, levels = c(2, 1), labels = c('Y_z', 'X_z'))\n  )\n```\n:::\n\n\n\n\nThe created data frame `pc_curves` has the predicted values of the X and Y coordinates *along the knots*. This is the same structure as @fig-tongue-xy, with the knot number on the *x*-axis and the coordinates on the *y*-axis. Of course, what we are after is the X/Y plot of the tongue contours, rather than the knot/coordinate plot as needed to fit an MFPCA. For the sake of clarity, we first plot the predicted curves for X and Y separately. @fig-pc-curves shows these. The plot is composed of four panels: the top two are the predicted curves along knot number for the Y coordinates (based on PC1 in the left panel and PC2 in the right panel). Interpreting the effect of the PCs on the X and Y coordinates separately allows one to observe vertical (Y coordinate) and horizontal (X coordinate) differences in tongue position independently. However, note that the vector of muscle contractions in the tongue are not simply along a vertical/horizontal axis [@honda1996; @wrench2024]. Looking at a full tongue contour (in an X/Y coordinates plot) will generally prove to be more straightforward.\n\n\n\n\n::: {#cell-fig-pc-curves .cell}\n\n```{.r .cell-code .hidden}\npc_curves |> \n  ggplot(aes(\n    x = knot, y = value, group = sd_frac, color = sd_frac\n  )) +\n  geom_line() +\n  scale_color_gradient2(\n    low = \"#762a83\", mid = \"grey\", high = \"#1b7837\",\n    breaks = c(-1, 0 , 1)\n  ) +\n  facet_grid(\n    cols = vars(PC), rows = vars(dim),\n    scales = \"free_y\",\n    labeller = labeller(PC = ~str_glue(\"PC{.x}\"))\n  ) +\n  labs(color = expression(frac(s[k], sigma[k]))) +\n  geom_line(\n    data = pc_curves |> filter(sd_frac == 0),\n    color = 'black', linewidth = 1.2\n  )\n```\n\n::: {.cell-output-display}\n![Predicted curves along knot number for X and Y coordinates, as obtained from an MFPCA.](index_files/figure-html/fig-pc-curves-1.png){#fig-pc-curves width=672}\n:::\n:::\n\n\n\n\nIn order to plot tongue contours in the X/Y coordinate system, we simply need to pivot the data to a wider format.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npc_curves_wide <- pc_curves |> \n  pivot_wider(names_from = dim)\n```\n:::\n\n\n\n\n@fig-contours plots the predicted contours based on the the PC scores (specifically, fractions of the standard deviation of the PC scores). The *x* and *y*-axes correspond to the X and Y coordinates of the tongue contour, with the effect of PC1 in the left panel and the effect of PC2 in the right panel. A higher PC1 score (green lines in the left panel) suggest a lowering of the tongue body/dorsum and raising of the tongue tip. Since the data contains velar and coronal consonants, we take this to be capturing the velar/coronal place of articulation effect. A higher PC2 score (green lines in the right panel) corresponds to an overall higher tongue position. Considering that the back/central vowels /a, o, u/ are included in this data set, we take PC2 to be related with the effect of vowel on the tongue shape at closure onset.\n\n\n\n\n::: {#cell-fig-contours .cell}\n\n```{.r .cell-code .hidden}\npc_curves_wide |> \n  ggplot(aes(x = X_z, y = Y_z, group = sd_frac, color = sd_frac)) +\n  geom_path() +\n  scale_color_gradient2(\n    low = \"#762a83\", mid = \"grey\", high = \"#1b7837\",\n    breaks = c(-1, 0 , 1)\n  ) +\n  facet_wrap(\n    vars(PC),\n    labeller = labeller(PC = ~str_glue(\"PC{.x}\"))\n  ) +\n  coord_fixed()\n```\n\n::: {.cell-output-display}\n![Predicted tongue contours as obtained from an MFPCA.](index_files/figure-html/fig-contours-1.png){#fig-contours width=672}\n:::\n:::\n\n\n\n\nGiven the patterns in @fig-contours, we can expect to see differences in PC2 scores based on the vowel if there is VC coarticulation. We can obtain the PC scores of each observation in the data with the following code.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npc_scores <- mfpca$scores |>\n  `colnames<-`(paste0(\"PC\", 1:n_pc)) |>\n  as_tibble() |>\n  bind_cols(dlc_voff_long |> distinct(frame_id, vowel, c2_place, language))\n```\n:::\n\n\n\n\n@fig-pc-scores plots PC scores by language (rows), consonant place (columns) and vowel (colour). Both in Italian and Polish, we can observe a clear coarticulatory effect of /u/ on the production of coronal stops (and perhaps minor differences in /a/ vs /o/). On the other hand, the effect of vowel in velar stops seems to be minimal, again in both languages. This is not entirely surprising, since while coronal stops allow for adjustments of (and coarticulatory effect on) the tongue body, velar stops do not since it is precisely the tongue body/dorsum that is raised to produce the velar closure.\n\n\n\n\n::: {#cell-fig-pc-scores .cell}\n\n```{.r .cell-code .hidden}\npc_scores |> \n  filter(PC2 < 0.5) |>\n  ggplot(aes(x = PC1, y = PC2, color = vowel)) +\n  geom_point() +\n  stat_ellipse() +\n  facet_grid(cols = vars(c2_place), rows = vars(language)) +\n  scale_color_brewer(palette = \"Dark2\")\n```\n\n::: {.cell-output-display}\n![PC1/PC2 scores by language, consonant place of articulation and vowel.](index_files/figure-html/fig-pc-scores-1.png){#fig-pc-scores width=672}\n:::\n:::\n\n\n\n\nOnce one has established which patterns each PC is capturing, PC scores can be submitted to further statistical modelling, like for example regression models where the PC scores are outcome variables and several predictors are include to assess possible differences in PC scores.\n\n### Emphaticness\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ndlc_emph_long <- dlc_emph_f |> \n  pivot_longer(c(X_z, Y_z), names_to = \"dim\") |> \n  group_by(dim, participant) |> \n  mutate(\n    value = (value - mean(value)) / sd(value)\n  ) |> \n  ungroup()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# build a multiFunData object\ncurves_fun_2d <- lapply(\n  c(\"X_z\", \"Y_z\"),\n  function(y) {\n    long2irregFunData(\n      dlc_emph_long |> filter(dim == {{y}}),\n      id = \"frame_id\",\n      time = \"knot\",\n      value = \"value\"\n    ) |> \n    as.funData()\n  }\n) |> \n  multiFunData()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Compute FPCA\nn_pc <- 2\nmfpca <- MFPCA(\n  curves_fun_2d,\n  M = n_pc,\n  uniExpansions = list(list(type = \"uFPCA\"), list(type = \"uFPCA\"))\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Proportion of explained variance\nmfpca$values  / sum(mfpca$values)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.7309506 0.2690494\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# scores st. dev.\nsd_fun <- sqrt(mfpca$values)\n\n# PC curves to be plotted\npc_curves <- expand_grid(\n  PC = 1:n_pc,\n  dim = 1:2, \n  sd_frac = seq(-1, 1, by = 0.25)\n) |> \n  group_by(PC, dim, sd_frac) |> \n  reframe(\n    funData2long1(\n      mfpca$meanFunction[[dim]] +\n        sd_frac * sd_fun[PC] * mfpca$functions[[dim]][PC],\n      time = \"knot\", value = \"value\"\n    )\n  ) |> \n  mutate(\n    dim = factor(dim, levels = c(2,1), labels = c('Y_z', 'X_z'))\n  )\n```\n:::\n\n::: {#cell-fig-emph-pc-curves .cell}\n\n```{.r .cell-code .hidden}\npc_curves |> \n  ggplot(aes(\n    x = knot, y = value, group = sd_frac, color = sd_frac\n  )) +\n  geom_line() +\n  scale_color_gradient2(\n    low = \"#762a83\", mid = \"grey\", high = \"#1b7837\",\n    breaks = c(-1, 0 , 1)\n  ) +\n  facet_grid(\n    cols = vars(PC), rows = vars(dim),\n    scales = \"free_y\",\n    labeller = labeller(PC = ~str_glue(\"PC{.x}\"))\n  ) +\n  labs(color = expression(frac(s[k], sigma[k]))) +\n  geom_line(\n    data = pc_curves |> filter(sd_frac == 0),\n    color = 'black', linewidth = 1.2\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/fig-emph-pc-curves-1.png){#fig-emph-pc-curves width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npc_curves_wide <- pc_curves |> \n  pivot_wider(names_from = dim)\n```\n:::\n\n::: {#cell-fig-emph-curves-wide .cell}\n\n```{.r .cell-code .hidden}\npc_curves_wide |> \n  ggplot(aes(x = X_z, y = Y_z, group = sd_frac, color = sd_frac)) +\n  geom_path() +\n  scale_color_gradient2(\n    low = \"#762a83\", mid = \"grey\", high = \"#1b7837\",\n    breaks = c(-1, 0 , 1)\n  ) +\n  facet_wrap(\n    vars(PC),\n    labeller = labeller(PC = ~str_glue(\"PC{.x}\"))\n  ) +\n  coord_fixed()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/fig-emph-curves-wide-1.png){#fig-emph-curves-wide width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# collect PC scores\npc_scores <- mfpca$scores |>\n  `colnames<-`( paste0(\"PC\", 1:n_pc)) |>\n  as_tibble() |>\n  bind_cols(dlc_emph_long |> distinct(frame_id, emph, vowel, participant))\n```\n:::\n\n::: {#cell-fig-emph-speakers .cell}\n\n```{.r .cell-code .hidden}\npc_scores |> \n  ggplot(aes(x = PC1, y = PC2, colour = emph, label = vowel)) +\n  geom_point(alpha = 0.5) +\n  scale_color_brewer(palette = \"Dark2\") +\n  stat_ellipse() +\n  facet_grid(cols = vars(participant), rows = vars(vowel))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/fig-emph-speakers-1.png){#fig-emph-speakers width=672}\n:::\n:::\n\n::: {#cell-fig-emph-pc1 .cell}\n\n```{.r .cell-code .hidden}\npc_scores |> \n  ggplot(aes(vowel, PC1, colour = emph)) +\n  geom_jitter(position = position_jitterdodge(jitter.width = 0.2), alpha = 0.25) +\n  scale_color_brewer(palette = \"Dark2\") +\n    facet_wrap(vars(participant))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/fig-emph-pc1-1.png){#fig-emph-pc1 width=672}\n:::\n:::\n\n::: {#cell-fig-emph-pc2 .cell}\n\n```{.r .cell-code .hidden}\npc_scores |> \n  ggplot(aes(vowel, PC2, colour = emph)) +\n  geom_jitter(position = position_jitterdodge(jitter.width = 0.2), alpha = 0.25) +\n  scale_color_brewer(palette = \"Dark2\") +\n    facet_wrap(vars(participant))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/fig-emph-pc2-1.png){#fig-emph-pc2 width=672}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}